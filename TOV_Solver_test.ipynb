{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "367bf8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from TOV_Solver import WaveNetTOV, evaluate_model\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from preprocessing import _resample_group, tov_load_and_preprocess\n",
    "from EOS_Solver import chi2_loss\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf880bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/sample_eos.csv\")\n",
    "test[\"rho\"] = test[\"rho\"]\n",
    "test[['ID', \"p\", 'rho']]\n",
    "unique_ids_test = test[\"ID\"].unique().tolist()\n",
    "\n",
    "max = test.rho.max()\n",
    "min = test.rho.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0c016be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set density range: 0.06 to 1.28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test set density range: {min} to {max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4d0770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>model</th>\n",
       "      <th>weight</th>\n",
       "      <th>e</th>\n",
       "      <th>p</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>RMFNL</td>\n",
       "      <td>1.217783e-06</td>\n",
       "      <td>47.410754</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>RMFNL</td>\n",
       "      <td>1.217783e-06</td>\n",
       "      <td>56.876734</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>RMFNL</td>\n",
       "      <td>1.217783e-06</td>\n",
       "      <td>66.353718</td>\n",
       "      <td>0.141353</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>RMFNL</td>\n",
       "      <td>1.217783e-06</td>\n",
       "      <td>75.839753</td>\n",
       "      <td>0.201318</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>RMFNL</td>\n",
       "      <td>1.217783e-06</td>\n",
       "      <td>85.334896</td>\n",
       "      <td>0.276774</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12263710</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>GDFMX</td>\n",
       "      <td>8.762089e-07</td>\n",
       "      <td>1632.385290</td>\n",
       "      <td>782.559500</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12263711</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>GDFMX</td>\n",
       "      <td>8.762089e-07</td>\n",
       "      <td>1651.929646</td>\n",
       "      <td>796.901111</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12263712</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>GDFMX</td>\n",
       "      <td>8.762089e-07</td>\n",
       "      <td>1671.587792</td>\n",
       "      <td>811.360000</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12263713</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>GDFMX</td>\n",
       "      <td>8.762089e-07</td>\n",
       "      <td>1691.359710</td>\n",
       "      <td>825.936003</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12263714</th>\n",
       "      <td>8293.0</td>\n",
       "      <td>GDFMX</td>\n",
       "      <td>8.762089e-07</td>\n",
       "      <td>1711.245387</td>\n",
       "      <td>840.628957</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  model        weight            e           p   rho\n",
       "0         8293.0  RMFNL  1.217783e-06    47.410754    0.031089  0.06\n",
       "1         8293.0  RMFNL  1.217783e-06    56.876734    0.087275  0.07\n",
       "2         8293.0  RMFNL  1.217783e-06    66.353718    0.141353  0.08\n",
       "3         8293.0  RMFNL  1.217783e-06    75.839753    0.201318  0.09\n",
       "4         8293.0  RMFNL  1.217783e-06    85.334896    0.276774  0.10\n",
       "...          ...    ...           ...          ...         ...   ...\n",
       "12263710  8293.0  GDFMX  8.762089e-07  1632.385290  782.559500  1.24\n",
       "12263711  8293.0  GDFMX  8.762089e-07  1651.929646  796.901111  1.25\n",
       "12263712  8293.0  GDFMX  8.762089e-07  1671.587792  811.360000  1.26\n",
       "12263713  8293.0  GDFMX  8.762089e-07  1691.359710  825.936003  1.27\n",
       "12263714  8293.0  GDFMX  8.762089e-07  1711.245387  840.628957  1.28\n",
       "\n",
       "[738 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.query(f\"ID == {unique_ids_test[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c906d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 64\n",
    "N_samples = 1000\n",
    "eos_data = pd.read_csv(\n",
    "    \"data/Monmoy/eos_cs2.csv\",\n",
    "    nrows = N_samples * 287 # for 40000 samples -> 11480000 rows ; here we have 287 rows per sample \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d68d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID   rho         p\n",
      "0   7  0.06  0.317310\n",
      "1   7  0.07  0.417404\n",
      "2   7  0.08  0.526109\n",
      "3   7  0.09  0.679272\n",
      "4   7  0.10  0.878662\n"
     ]
    }
   ],
   "source": [
    "rho_grid = np.round(np.arange(0.06, 1.28 + 1e-12, 0.01), 2)\n",
    "\n",
    "ID_COL = \"ID\"\n",
    "RHO_COL = \"rho\"\n",
    "P_COL = \"p\"\n",
    "\n",
    "def interp_one_id(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    # group key value (the ID)\n",
    "    id_value = g.name\n",
    "\n",
    "    g = g[[RHO_COL, P_COL]].copy()\n",
    "\n",
    "    g = g.sort_values(RHO_COL)\n",
    "    g = g.groupby(RHO_COL, as_index=False)[P_COL].mean()\n",
    "\n",
    "    x = g[RHO_COL].to_numpy()\n",
    "    y = g[P_COL].to_numpy()\n",
    "\n",
    "    if len(x) < 2:\n",
    "        return pd.DataFrame({ID_COL: id_value, RHO_COL: rho_grid, P_COL: np.nan})\n",
    "\n",
    "    y_grid = np.interp(rho_grid, x, y, left=np.nan, right=np.nan)\n",
    "\n",
    "    return pd.DataFrame({ID_COL: id_value, RHO_COL: rho_grid, P_COL: y_grid})\n",
    "\n",
    "eos_interp = (\n",
    "    eos_data\n",
    "    .dropna(subset=[ID_COL, RHO_COL, P_COL])\n",
    "    .groupby(ID_COL, group_keys=False)\n",
    "    .apply(interp_one_id)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(eos_interp.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf8628fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_data = eos_interp.copy()\n",
    "eos_data['model'] = \"RMF\"\n",
    "unique_ids = eos_data[\"ID\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56a4b78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ec</th>\n",
       "      <th>M</th>\n",
       "      <th>R</th>\n",
       "      <th>Lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>289.411765</td>\n",
       "      <td>0.812132</td>\n",
       "      <td>12.897442</td>\n",
       "      <td>8729.581483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>313.613445</td>\n",
       "      <td>0.994052</td>\n",
       "      <td>12.847777</td>\n",
       "      <td>3211.489512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>337.815126</td>\n",
       "      <td>1.172509</td>\n",
       "      <td>12.863732</td>\n",
       "      <td>1380.417947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>362.016807</td>\n",
       "      <td>1.337366</td>\n",
       "      <td>12.895802</td>\n",
       "      <td>683.882018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>386.218487</td>\n",
       "      <td>1.487452</td>\n",
       "      <td>12.923066</td>\n",
       "      <td>376.615989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34227</th>\n",
       "      <td>6686</td>\n",
       "      <td>894.453782</td>\n",
       "      <td>2.563226</td>\n",
       "      <td>12.432985</td>\n",
       "      <td>5.885787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34228</th>\n",
       "      <td>6686</td>\n",
       "      <td>918.655462</td>\n",
       "      <td>2.564164</td>\n",
       "      <td>12.404504</td>\n",
       "      <td>5.707931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34229</th>\n",
       "      <td>6686</td>\n",
       "      <td>942.857143</td>\n",
       "      <td>2.564527</td>\n",
       "      <td>12.385730</td>\n",
       "      <td>5.598142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34230</th>\n",
       "      <td>6686</td>\n",
       "      <td>967.058824</td>\n",
       "      <td>2.564620</td>\n",
       "      <td>12.373439</td>\n",
       "      <td>5.529952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34231</th>\n",
       "      <td>6686</td>\n",
       "      <td>991.260504</td>\n",
       "      <td>2.564597</td>\n",
       "      <td>12.365421</td>\n",
       "      <td>5.487496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34232 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID          ec         M          R       Lambda\n",
       "0         7  289.411765  0.812132  12.897442  8729.581483\n",
       "1         7  313.613445  0.994052  12.847777  3211.489512\n",
       "2         7  337.815126  1.172509  12.863732  1380.417947\n",
       "3         7  362.016807  1.337366  12.895802   683.882018\n",
       "4         7  386.218487  1.487452  12.923066   376.615989\n",
       "...     ...         ...       ...        ...          ...\n",
       "34227  6686  894.453782  2.563226  12.432985     5.885787\n",
       "34228  6686  918.655462  2.564164  12.404504     5.707931\n",
       "34229  6686  942.857143  2.564527  12.385730     5.598142\n",
       "34230  6686  967.058824  2.564620  12.373439     5.529952\n",
       "34231  6686  991.260504  2.564597  12.365421     5.487496\n",
       "\n",
       "[34232 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_data = pd.read_csv(\"data/Monmoy/mr_cs2.csv\")\n",
    "mr_data = mr_data[mr_data[\"ID\"].isin(unique_ids)]\n",
    "mr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6703b40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_data.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b41483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_df = eos_data.copy()\n",
    "# Np = 64\n",
    "\n",
    "# # --- Normalize density (ρ / ρ_sat) ---\n",
    "# input_df[\"rho\"] = input_df[\"rho\"] / 0.16\n",
    "\n",
    "# # --- Resample EoS and MR curves ---\n",
    "# input_interp = input_df.groupby([\"ID\", \"model\"], group_keys=False).apply(\n",
    "#     _resample_group, column=\"rho\", Np=Np, include_groups=True\n",
    "# )\n",
    "\n",
    "\n",
    "# # --- Prepare arrays ---\n",
    "# N = input_df.ID.nunique()\n",
    "# X = np.zeros((N, Np, 2), dtype=np.float32)\n",
    "\n",
    "# # --- Build dataset ---\n",
    "# for i in range(N):\n",
    "#     ID = unique_ids[i]\n",
    "#     eos_grp = input_interp.loc[(input_interp[\"ID\"] == ID)]\n",
    "\n",
    "#     # log10(p)\n",
    "#     p_vals = eos_grp[\"p\"].to_numpy()\n",
    "\n",
    "#     X[i, :, 1] = np.log10(np.clip(p_vals, 1e-30, None))\n",
    "\n",
    "#     rho_phys = input_df[\"rho\"].loc[(input_df[\"ID\"] == ID) ].to_numpy(dtype=np.float32)\n",
    "#     rho_min, rho_max = float(rho_phys.min()), float(rho_phys.max())\n",
    "\n",
    "#     rho_phys_targets = np.linspace(rho_min, rho_max, Np, dtype=np.float32)\n",
    "#     rho_scaled = 0.1 * (rho_phys_targets - rho_min) / (rho_max - rho_min)\n",
    "\n",
    "#     X[i, :, 0] = rho_scaled\n",
    "\n",
    "#     if i % 1000 == 0:\n",
    "#         print(f\"Processed {i}/{N}\")\n",
    "\n",
    "# # --- Scale X globally ---\n",
    "# X_max = np.load(\"scalers/X_MAX.npy\")\n",
    "# X_scaled = X.copy()\n",
    "# X_scaled[:, :, 1] = X[:, :, 1] / X_max\n",
    "\n",
    "# np.save(\"data/Monmoy/X_scaled.npy\", X_scaled)\n",
    "\n",
    "# X_scaled = np.load(\"data/Monmoy/X_scaled.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86807bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = np.load(\"data/Monmoy/X_scaled.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "348e6ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.10.0+cpu\n",
      "cuda available: False\n",
      "torch cuda version: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"torch cuda version:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4fc985b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m ckpt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/tov_solver.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 3️⃣ If it’s a dict:\u001b[39;00m\n\u001b[32m      6\u001b[39m model = WaveNetTOV().to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppsan\\repos\\NN-Reconstruction\\nvenv\\Lib\\site-packages\\torch\\serialization.py:1540\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1547\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1548\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppsan\\repos\\NN-Reconstruction\\nvenv\\Lib\\site-packages\\torch\\serialization.py:2143\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2141\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2142\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2143\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2144\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2146\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppsan\\repos\\NN-Reconstruction\\nvenv\\Lib\\site-packages\\torch\\_weights_only_unpickler.py:539\u001b[39m, in \u001b[36mUnpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    531\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    532\u001b[39m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    533\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) > \u001b[32m0\u001b[39m\n\u001b[32m    534\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.serialization._maybe_decode_ascii(pid[\u001b[32m0\u001b[39m]) != \u001b[33m\"\u001b[39m\u001b[33mstorage\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    535\u001b[39m     ):\n\u001b[32m    536\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[32m    537\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pid[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[32m0\u001b[39m], LONG_BINGET[\u001b[32m0\u001b[39m]]:\n\u001b[32m    541\u001b[39m     idx = (read(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[32m0\u001b[39m] == BINGET[\u001b[32m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, read(\u001b[32m4\u001b[39m)))[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppsan\\repos\\NN-Reconstruction\\nvenv\\Lib\\site-packages\\torch\\serialization.py:2107\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2106\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2107\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2109\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppsan\\repos\\NN-Reconstruction\\nvenv\\Lib\\site-packages\\torch\\serialization.py:2073\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[32m   2072\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._guards.detect_fake_mode(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2073\u001b[39m     wrap_storage = \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2075\u001b[39m     storage._fake_device = location\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppsan\\repos\\NN-Reconstruction\\nvenv\\Lib\\site-packages\\torch\\serialization.py:1884\u001b[39m, in \u001b[36m_get_restore_location.<locals>.restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m   1883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrestore_location\u001b[39m(storage, location):\n\u001b[32m-> \u001b[39m\u001b[32m1884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_restore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppsan\\repos\\NN-Reconstruction\\nvenv\\Lib\\site-packages\\torch\\serialization.py:707\u001b[39m, in \u001b[36mdefault_restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    688\u001b[39m \u001b[33;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[32m    689\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    704\u001b[39m \u001b[33;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[32m    705\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppsan\\repos\\NN-Reconstruction\\nvenv\\Lib\\site-packages\\torch\\serialization.py:640\u001b[39m, in \u001b[36m_deserialize\u001b[39m\u001b[34m(backend_name, obj, location)\u001b[39m\n\u001b[32m    638\u001b[39m     backend_name = torch._C._get_privateuse1_backend_name()\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location.startswith(backend_name):\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     device = \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.to(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppsan\\repos\\NN-Reconstruction\\nvenv\\Lib\\site-packages\\torch\\serialization.py:609\u001b[39m, in \u001b[36m_validate_device\u001b[39m\u001b[34m(location, backend_name)\u001b[39m\n\u001b[32m    607\u001b[39m     device_index = device.index \u001b[38;5;28;01mif\u001b[39;00m device.index \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mis_available\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module.is_available():\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    610\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    611\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.is_available() is False. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    612\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you are running on a CPU-only machine, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    613\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    614\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto map your storages to the CPU.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m     )\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mdevice_count\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    617\u001b[39m     device_count = device_module.device_count()\n",
      "\u001b[31mRuntimeError\u001b[39m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "ckpt = torch.load(\"models/tov_solver.pt\", map_location=device)\n",
    "\n",
    "# 3️⃣ If it’s a dict:\n",
    "model = WaveNetTOV().to(device)\n",
    "model.load_state_dict(ckpt)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tensors\n",
    "X_test = torch.tensor(X_scaled[:,:,1:2], dtype=torch.float32).to(device)\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    pred = model(X_test)\n",
    "pred = pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_MAX = np.load(\"scalers/M_MAX.npy\")\n",
    "R_MAX = 16.0\n",
    "R_MIN = np.load(\"scalers/R_MIN.npy\")\n",
    "\n",
    "mass_pred_unscaled = pred[:, :, 0]  * M_MAX\n",
    "radius_pred_unscaled = pred[:, :, 1] * (R_MAX - R_MIN) + R_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single sample (set `idx` to choose which sample)\n",
    "idx = 0\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# True M-R relation (black)\n",
    "ax.scatter(\n",
    "    mr_data.query(f\"ID == @unique_ids[{idx}]\").R.values,\n",
    "    mr_data.query(f\"ID == @unique_ids[{idx}]\").M.values,\n",
    "    color='black',\n",
    "    label='True'\n",
    ")\n",
    "\n",
    "# Predicted M-R relation (red dashed)\n",
    "ax.plot(\n",
    "    radius_pred_unscaled[idx],\n",
    "    mass_pred_unscaled[idx],\n",
    "    \"--\",\n",
    "    color='red',\n",
    "    label='Predicted'\n",
    ")\n",
    "\n",
    "ax.set_title(f'Sample {idx + 1}')\n",
    "ax.set_xlabel('Radius')\n",
    "ax.set_ylabel('Mass')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65789d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_to_plot = 10\n",
    "fig, axes = plt.subplots(2, 5, figsize=(18, 7))  # 2 rows × 5 cols\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(n_samples_to_plot):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # True M-R relation (black)\n",
    "    ax.scatter(\n",
    "        mr_data.query(f\"ID == @unique_ids[{i}]\").R.values,\n",
    "        mr_data.query(f\"ID == @unique_ids[{i}]\").M.values,\n",
    "        color='black',\n",
    "        label='True'\n",
    "    )\n",
    "\n",
    "    # Predicted M-R relation (red dashed)\n",
    "    ax.plot(\n",
    "        radius_pred_unscaled[i],\n",
    "        mass_pred_unscaled[i],\n",
    "        \"--\",\n",
    "        color='red',\n",
    "        label='Predicted'\n",
    "    )\n",
    "\n",
    "    ax.set_title(f'Sample {i + 1}')\n",
    "    ax.set_xlabel('Radius')\n",
    "    ax.set_ylabel('Mass')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Only show legend once (cleaner look)\n",
    "    if i == 0:\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9597af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dM = np.ones_like(radius_pred_unscaled[0], dtype=np.float32)\n",
    "dR = np.ones_like(radius_pred_unscaled[0], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c087e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0.0\n",
    "mass_chi2_term = 0.0\n",
    "radius_chi2_term = 0.0\n",
    "\n",
    "for k in range(N_samples):  # k indexes IDs\n",
    "    mr_pred_t = torch.tensor(pred[k], dtype=torch.float32).unsqueeze(0)\n",
    "    M_seq, R_seq = mr_pred_t[0,:,0], mr_pred_t[0,:,1]\n",
    "\n",
    "    mr_data_ = mr_data.query(f\"ID == @unique_ids[{k}]\")\n",
    "    m_obs_t = torch.tensor(mr_data_.M.values / M_MAX, dtype=torch.float32)\n",
    "    r_obs_t = torch.tensor((mr_data_.R.values - R_MIN) / (R_MAX - R_MIN), dtype=torch.float32)\n",
    "    dM_t = torch.tensor(dM, dtype=torch.float32)\n",
    "    dR_t = torch.tensor(dR, dtype=torch.float32)\n",
    "\n",
    "    for j in range(len(m_obs_t)):  # j indexes observations for that ID\n",
    "        distances = ((M_seq - m_obs_t[j])/(dM_t[j] + 1e-6))**2 + \\\n",
    "                    ((R_seq - r_obs_t[j])/(dR_t[j] + 1e-6))**2\n",
    "\n",
    "        min_idx = torch.argmin(distances)\n",
    "\n",
    "        m_term = ((M_seq[min_idx] - m_obs_t[j])/(dM_t[j] + 1e-6))**2\n",
    "        r_term = ((R_seq[min_idx] - r_obs_t[j])/(dR_t[j] + 1e-6))**2\n",
    "\n",
    "        total_loss += m_term + r_term\n",
    "        mass_chi2_term += m_term\n",
    "        radius_chi2_term += r_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Mass chi2 term:\", mass_chi2_term.item()/N_samples)\n",
    "print(\"Radius chi2 term:\", radius_chi2_term.item()/N_samples)\n",
    "print(f\"Total Chi² Loss over test set: {total_loss/(N_samples)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
